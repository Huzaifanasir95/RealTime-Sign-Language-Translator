{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üì∏ Data Collection - Sign Language Gestures\n",
                "\n",
                "This notebook helps you collect hand landmark data for sign language gestures using your webcam and MediaPipe.\n",
                "\n",
                "## Objectives\n",
                "- Define sign language classes to collect\n",
                "- Use MediaPipe to detect and extract hand landmarks\n",
                "- Collect multiple samples per gesture class\n",
                "- Save data for preprocessing\n",
                "\n",
                "## What You'll Collect\n",
                "- **21 hand landmarks** per hand (x, y, z coordinates)\n",
                "- **63 features** total (21 landmarks √ó 3 coordinates)\n",
                "- **Multiple samples** per gesture for robust training\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Import Required Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import cv2\n",
                "import mediapipe as mp\n",
                "from datetime import datetime\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from tqdm import tqdm\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "print(\"‚úÖ Libraries imported successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Initialize MediaPipe"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize MediaPipe Hands\n",
                "mp_hands = mp.solutions.hands\n",
                "mp_drawing = mp.solutions.drawing_utils\n",
                "mp_drawing_styles = mp.solutions.drawing_styles\n",
                "\n",
                "print(\"‚úÖ MediaPipe initialized\")\n",
                "print(f\"   MediaPipe version: {mp.__version__}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Configuration Settings"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Data collection settings\n",
                "DATA_DIR = 'data/raw'\n",
                "os.makedirs(DATA_DIR, exist_ok=True)\n",
                "\n",
                "# Define your sign language classes\n",
                "# Start with ASL alphabet letters or common words\n",
                "CLASSES = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'L']\n",
                "\n",
                "# Number of samples to collect per class\n",
                "SAMPLES_PER_CLASS = 200  # Increase for better accuracy\n",
                "\n",
                "# MediaPipe detection settings\n",
                "MIN_DETECTION_CONFIDENCE = 0.7\n",
                "MIN_TRACKING_CONFIDENCE = 0.7\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"DATA COLLECTION CONFIGURATION\")\n",
                "print(\"=\"*60)\n",
                "print(f\"Classes to collect: {CLASSES}\")\n",
                "print(f\"Total classes: {len(CLASSES)}\")\n",
                "print(f\"Samples per class: {SAMPLES_PER_CLASS}\")\n",
                "print(f\"Total samples to collect: {len(CLASSES) * SAMPLES_PER_CLASS}\")\n",
                "print(f\"Detection confidence: {MIN_DETECTION_CONFIDENCE}\")\n",
                "print(f\"Tracking confidence: {MIN_TRACKING_CONFIDENCE}\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Data Collection Function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def collect_data_for_class(class_name, num_samples=200):\n",
                "    \"\"\"\n",
                "    Collect hand landmark data for a specific sign language gesture.\n",
                "    \n",
                "    Args:\n",
                "        class_name (str): Name of the gesture class (e.g., 'A', 'B', 'Hello')\n",
                "        num_samples (int): Number of samples to collect\n",
                "    \n",
                "    Returns:\n",
                "        tuple: (data, labels) - Lists of landmark data and corresponding labels\n",
                "    \"\"\"\n",
                "    data = []\n",
                "    labels = []\n",
                "    \n",
                "    cap = cv2.VideoCapture(0)\n",
                "    \n",
                "    # Set camera properties for better quality\n",
                "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
                "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
                "    cap.set(cv2.CAP_PROP_FPS, 30)\n",
                "    \n",
                "    with mp_hands.Hands(\n",
                "        static_image_mode=False,\n",
                "        max_num_hands=1,  # Collect one hand at a time\n",
                "        min_detection_confidence=MIN_DETECTION_CONFIDENCE,\n",
                "        min_tracking_confidence=MIN_TRACKING_CONFIDENCE\n",
                "    ) as hands:\n",
                "        \n",
                "        print(f\"\\n{'='*60}\")\n",
                "        print(f\"Collecting data for: {class_name}\")\n",
                "        print(f\"{'='*60}\")\n",
                "        print(\"\\nInstructions:\")\n",
                "        print(\"  1. Position your hand in front of the camera\")\n",
                "        print(\"  2. Make the sign for '{}'\" .format(class_name))\n",
                "        print(\"  3. Press SPACE to start collecting\")\n",
                "        print(\"  4. Keep your hand steady and visible\")\n",
                "        print(\"  5. Press ESC to skip this class\\n\")\n",
                "        \n",
                "        # Wait for user to get ready\n",
                "        ready = False\n",
                "        while not ready:\n",
                "            ret, frame = cap.read()\n",
                "            if not ret:\n",
                "                print(\"‚ùå Error: Cannot read from webcam\")\n",
                "                break\n",
                "                \n",
                "            frame = cv2.flip(frame, 1)  # Mirror the image\n",
                "            \n",
                "            # Add instructions overlay\n",
                "            cv2.rectangle(frame, (0, 0), (frame.shape[1], 120), (0, 0, 0), -1)\n",
                "            cv2.putText(frame, f\"Class: {class_name}\", (20, 40), \n",
                "                       cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)\n",
                "            cv2.putText(frame, \"Press SPACE to start | ESC to skip\", (20, 80), \n",
                "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
                "            \n",
                "            cv2.imshow('Data Collection', frame)\n",
                "            \n",
                "            key = cv2.waitKey(1) & 0xFF\n",
                "            if key == 32:  # SPACE\n",
                "                ready = True\n",
                "            elif key == 27:  # ESC\n",
                "                print(f\"‚è≠Ô∏è  Skipped class: {class_name}\")\n",
                "                cap.release()\n",
                "                cv2.destroyAllWindows()\n",
                "                return data, labels\n",
                "        \n",
                "        # Countdown before collection\n",
                "        for i in range(3, 0, -1):\n",
                "            ret, frame = cap.read()\n",
                "            frame = cv2.flip(frame, 1)\n",
                "            cv2.putText(frame, f\"Starting in {i}...\", (frame.shape[1]//2 - 150, frame.shape[0]//2), \n",
                "                       cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 255), 4)\n",
                "            cv2.imshow('Data Collection', frame)\n",
                "            cv2.waitKey(1000)\n",
                "        \n",
                "        # Collect samples\n",
                "        sample_count = 0\n",
                "        failed_detections = 0\n",
                "        \n",
                "        print(f\"\\nüì∏ Collecting {num_samples} samples...\")\n",
                "        \n",
                "        with tqdm(total=num_samples, desc=f\"Class {class_name}\") as pbar:\n",
                "            while sample_count < num_samples:\n",
                "                ret, frame = cap.read()\n",
                "                if not ret:\n",
                "                    break\n",
                "                \n",
                "                frame = cv2.flip(frame, 1)\n",
                "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
                "                \n",
                "                # Process with MediaPipe\n",
                "                results = hands.process(rgb_frame)\n",
                "                \n",
                "                if results.multi_hand_landmarks:\n",
                "                    for hand_landmarks in results.multi_hand_landmarks:\n",
                "                        # Draw landmarks on frame\n",
                "                        mp_drawing.draw_landmarks(\n",
                "                            frame,\n",
                "                            hand_landmarks,\n",
                "                            mp_hands.HAND_CONNECTIONS,\n",
                "                            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
                "                            mp_drawing_styles.get_default_hand_connections_style()\n",
                "                        )\n",
                "                        \n",
                "                        # Extract landmarks (x, y, z for each of 21 landmarks)\n",
                "                        landmarks = []\n",
                "                        for lm in hand_landmarks.landmark:\n",
                "                            landmarks.extend([lm.x, lm.y, lm.z])\n",
                "                        \n",
                "                        # Store data\n",
                "                        data.append(landmarks)\n",
                "                        labels.append(class_name)\n",
                "                        sample_count += 1\n",
                "                        pbar.update(1)\n",
                "                        \n",
                "                        # Visual feedback - green border when capturing\n",
                "                        cv2.rectangle(frame, (0, 0), (frame.shape[1], frame.shape[0]), \n",
                "                                    (0, 255, 0), 10)\n",
                "                else:\n",
                "                    failed_detections += 1\n",
                "                    # Red border when no hand detected\n",
                "                    cv2.rectangle(frame, (0, 0), (frame.shape[1], frame.shape[0]), \n",
                "                                (0, 0, 255), 10)\n",
                "                \n",
                "                # Display progress overlay\n",
                "                cv2.rectangle(frame, (0, 0), (frame.shape[1], 120), (0, 0, 0), -1)\n",
                "                cv2.putText(frame, f\"Class: {class_name}\", (20, 40), \n",
                "                           cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)\n",
                "                cv2.putText(frame, f\"Progress: {sample_count}/{num_samples}\", (20, 80), \n",
                "                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
                "                \n",
                "                # Progress bar\n",
                "                bar_width = int((sample_count / num_samples) * (frame.shape[1] - 40))\n",
                "                cv2.rectangle(frame, (20, 95), (20 + bar_width, 110), (0, 255, 0), -1)\n",
                "                cv2.rectangle(frame, (20, 95), (frame.shape[1] - 20, 110), (255, 255, 255), 2)\n",
                "                \n",
                "                cv2.imshow('Data Collection', frame)\n",
                "                \n",
                "                if cv2.waitKey(1) & 0xFF == 27:  # ESC to stop\n",
                "                    print(f\"\\n‚èπÔ∏è  Collection stopped by user\")\n",
                "                    break\n",
                "    \n",
                "    cap.release()\n",
                "    cv2.destroyAllWindows()\n",
                "    \n",
                "    # Summary\n",
                "    print(f\"\\n‚úÖ Collection complete for '{class_name}'\")\n",
                "    print(f\"   Samples collected: {len(data)}\")\n",
                "    print(f\"   Failed detections: {failed_detections}\")\n",
                "    if len(data) > 0:\n",
                "        success_rate = (len(data) / (len(data) + failed_detections)) * 100\n",
                "        print(f\"   Success rate: {success_rate:.1f}%\")\n",
                "    \n",
                "    return data, labels"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Collect Data for All Classes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize storage\n",
                "all_data = []\n",
                "all_labels = []\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"STARTING DATA COLLECTION\")\n",
                "print(\"=\"*60)\n",
                "print(f\"Total classes: {len(CLASSES)}\")\n",
                "print(f\"Samples per class: {SAMPLES_PER_CLASS}\")\n",
                "print(f\"Estimated time: ~{len(CLASSES) * 2} minutes\\n\")\n",
                "\n",
                "# Collect data for each class\n",
                "for idx, class_name in enumerate(CLASSES, 1):\n",
                "    print(f\"\\n[{idx}/{len(CLASSES)}] Preparing to collect: {class_name}\")\n",
                "    \n",
                "    data, labels = collect_data_for_class(class_name, SAMPLES_PER_CLASS)\n",
                "    \n",
                "    all_data.extend(data)\n",
                "    all_labels.extend(labels)\n",
                "    \n",
                "    # Short break between classes\n",
                "    if idx < len(CLASSES):\n",
                "        print(f\"\\n‚è∏Ô∏è  Take a 5-second break before next class...\")\n",
                "        import time\n",
                "        time.sleep(5)\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"DATA COLLECTION COMPLETE!\")\n",
                "print(\"=\"*60)\n",
                "print(f\"Total samples collected: {len(all_data)}\")\n",
                "print(f\"Total labels: {len(all_labels)}\")\n",
                "print(f\"Unique classes: {len(set(all_labels))}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Visualize Collected Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Count samples per class\n",
                "from collections import Counter\n",
                "\n",
                "class_counts = Counter(all_labels)\n",
                "\n",
                "# Create visualization\n",
                "plt.figure(figsize=(12, 6))\n",
                "classes = list(class_counts.keys())\n",
                "counts = list(class_counts.values())\n",
                "\n",
                "bars = plt.bar(classes, counts, color='skyblue', edgecolor='navy', linewidth=1.5)\n",
                "\n",
                "# Add value labels on bars\n",
                "for bar in bars:\n",
                "    height = bar.get_height()\n",
                "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
                "            f'{int(height)}',\n",
                "            ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
                "\n",
                "plt.xlabel('Sign Language Class', fontsize=12, fontweight='bold')\n",
                "plt.ylabel('Number of Samples', fontsize=12, fontweight='bold')\n",
                "plt.title('Collected Data Distribution', fontsize=14, fontweight='bold')\n",
                "plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
                "plt.tight_layout()\n",
                "\n",
                "# Save plot\n",
                "os.makedirs('outputs/visualizations', exist_ok=True)\n",
                "plt.savefig('outputs/visualizations/data_collection_distribution.png', \n",
                "            dpi=300, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "# Print statistics\n",
                "print(\"\\nClass Distribution:\")\n",
                "print(\"=\"*40)\n",
                "for class_name, count in sorted(class_counts.items()):\n",
                "    print(f\"  {class_name:10s}: {count:4d} samples\")\n",
                "print(\"=\"*40)\n",
                "print(f\"  {'Total':10s}: {sum(counts):4d} samples\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Save Collected Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convert to numpy arrays\n",
                "data_array = np.array(all_data)\n",
                "labels_array = np.array(all_labels)\n",
                "\n",
                "print(\"Data shape:\", data_array.shape)\n",
                "print(\"Labels shape:\", labels_array.shape)\n",
                "\n",
                "# Save as numpy files\n",
                "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
                "data_filename = os.path.join(DATA_DIR, f'landmarks_{timestamp}.npy')\n",
                "labels_filename = os.path.join(DATA_DIR, f'labels_{timestamp}.npy')\n",
                "\n",
                "np.save(data_filename, data_array)\n",
                "np.save(labels_filename, labels_array)\n",
                "\n",
                "# Also save as latest (for easy loading)\n",
                "np.save(os.path.join(DATA_DIR, 'landmarks.npy'), data_array)\n",
                "np.save(os.path.join(DATA_DIR, 'labels.npy'), labels_array)\n",
                "\n",
                "print(f\"\\n‚úÖ Data saved successfully!\")\n",
                "print(f\"   Timestamped files:\")\n",
                "print(f\"     - {data_filename}\")\n",
                "print(f\"     - {labels_filename}\")\n",
                "print(f\"   Latest files:\")\n",
                "print(f\"     - data/raw/landmarks.npy\")\n",
                "print(f\"     - data/raw/labels.npy\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Create Metadata File"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create metadata dictionary\n",
                "metadata = {\n",
                "    'collection_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
                "    'total_samples': len(all_data),\n",
                "    'num_classes': len(set(all_labels)),\n",
                "    'classes': sorted(list(set(all_labels))),\n",
                "    'samples_per_class': dict(class_counts),\n",
                "    'feature_dimension': len(all_data[0]) if all_data else 0,\n",
                "    'mediapipe_version': mp.__version__,\n",
                "    'detection_confidence': MIN_DETECTION_CONFIDENCE,\n",
                "    'tracking_confidence': MIN_TRACKING_CONFIDENCE\n",
                "}\n",
                "\n",
                "# Save metadata as JSON\n",
                "import json\n",
                "\n",
                "metadata_filename = os.path.join(DATA_DIR, f'metadata_{timestamp}.json')\n",
                "with open(metadata_filename, 'w') as f:\n",
                "    json.dump(metadata, f, indent=4)\n",
                "\n",
                "# Also save as latest\n",
                "with open(os.path.join(DATA_DIR, 'metadata.json'), 'w') as f:\n",
                "    json.dump(metadata, f, indent=4)\n",
                "\n",
                "print(\"\\n‚úÖ Metadata saved!\")\n",
                "print(\"\\nMetadata Summary:\")\n",
                "print(json.dumps(metadata, indent=2))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Data Quality Check"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check for any issues\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"DATA QUALITY CHECK\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Check for missing values\n",
                "has_nan = np.isnan(data_array).any()\n",
                "print(f\"\\n1. Missing values (NaN): {'‚ùå Found' if has_nan else '‚úÖ None'}\")\n",
                "\n",
                "# Check for infinite values\n",
                "has_inf = np.isinf(data_array).any()\n",
                "print(f\"2. Infinite values: {'‚ùå Found' if has_inf else '‚úÖ None'}\")\n",
                "\n",
                "# Check data shape consistency\n",
                "expected_features = 63  # 21 landmarks √ó 3 coordinates\n",
                "actual_features = data_array.shape[1]\n",
                "print(f\"3. Feature dimension: {actual_features} {'‚úÖ Correct' if actual_features == expected_features else '‚ùå Incorrect'}\")\n",
                "\n",
                "# Check class balance\n",
                "min_samples = min(class_counts.values())\n",
                "max_samples = max(class_counts.values())\n",
                "balance_ratio = min_samples / max_samples if max_samples > 0 else 0\n",
                "print(f\"4. Class balance ratio: {balance_ratio:.2f} {'‚úÖ Good' if balance_ratio > 0.8 else '‚ö†Ô∏è Imbalanced'}\")\n",
                "\n",
                "# Check value ranges\n",
                "print(f\"\\n5. Value Ranges:\")\n",
                "print(f\"   Min value: {data_array.min():.4f}\")\n",
                "print(f\"   Max value: {data_array.max():.4f}\")\n",
                "print(f\"   Mean value: {data_array.mean():.4f}\")\n",
                "print(f\"   Std deviation: {data_array.std():.4f}\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "if not has_nan and not has_inf and actual_features == expected_features:\n",
                "    print(\"‚úÖ Data quality check PASSED!\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è Data quality issues detected. Review before proceeding.\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üéØ Summary\n",
                "\n",
                "You have successfully collected sign language gesture data!\n",
                "\n",
                "### What's Next?\n",
                "Proceed to **03_data_preprocessing.ipynb** to:\n",
                "- Load and clean the collected data\n",
                "- Normalize and augment the dataset\n",
                "- Split into training, validation, and test sets\n",
                "- Prepare data for model training\n",
                "\n",
                "### Tips for Better Data Collection\n",
                "- Collect data in different lighting conditions\n",
                "- Vary hand positions and angles\n",
                "- Include samples from different people (if possible)\n",
                "- Ensure consistent gesture formation\n",
                "\n",
                "---"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}