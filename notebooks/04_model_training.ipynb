{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üß† Model Training - Deep Learning for Sign Language\n",
                "\n",
                "This notebook builds and trains a deep neural network for sign language gesture classification.\n",
                "\n",
                "## Objectives\n",
                "- Load preprocessed data\n",
                "- Build deep learning model architecture\n",
                "- Configure training parameters and callbacks\n",
                "- Train the model\n",
                "- Visualize training progress\n",
                "- Save the trained model\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Import Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import pickle\n",
                "import json\n",
                "from datetime import datetime\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# TensorFlow and Keras\n",
                "import tensorflow as tf\n",
                "from tensorflow import keras\n",
                "from tensorflow.keras import layers, models\n",
                "from tensorflow.keras.utils import to_categorical\n",
                "from tensorflow.keras.callbacks import (\n",
                "    ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, \n",
                "    TensorBoard, CSVLogger\n",
                ")\n",
                "\n",
                "# Set random seeds\n",
                "np.random.seed(42)\n",
                "tf.random.set_seed(42)\n",
                "\n",
                "print(\"‚úÖ Libraries imported successfully\")\n",
                "print(f\"TensorFlow version: {tf.__version__}\")\n",
                "print(f\"Keras version: {keras.__version__}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Processed Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load preprocessed data\n",
                "PROCESSED_DIR = 'data/processed'\n",
                "MODELS_DIR = 'models/saved_models'\n",
                "LOGS_DIR = 'outputs/logs'\n",
                "os.makedirs(MODELS_DIR, exist_ok=True)\n",
                "os.makedirs(LOGS_DIR, exist_ok=True)\n",
                "\n",
                "X_train = np.load(os.path.join(PROCESSED_DIR, 'X_train.npy'))\n",
                "X_val = np.load(os.path.join(PROCESSED_DIR, 'X_val.npy'))\n",
                "X_test = np.load(os.path.join(PROCESSED_DIR, 'X_test.npy'))\n",
                "y_train = np.load(os.path.join(PROCESSED_DIR, 'y_train.npy'))\n",
                "y_val = np.load(os.path.join(PROCESSED_DIR, 'y_val.npy'))\n",
                "y_test = np.load(os.path.join(PROCESSED_DIR, 'y_test.npy'))\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"DATA LOADED\")\n",
                "print(\"=\"*60)\n",
                "print(f\"Training set:   {X_train.shape}\")\n",
                "print(f\"Validation set: {X_val.shape}\")\n",
                "print(f\"Test set:       {X_test.shape}\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load label encoder\n",
                "with open('models/label_encoder.pkl', 'rb') as f:\n",
                "    label_encoder = pickle.load(f)\n",
                "\n",
                "num_classes = len(label_encoder.classes_)\n",
                "\n",
                "print(f\"\\nNumber of classes: {num_classes}\")\n",
                "print(f\"Classes: {label_encoder.classes_}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convert labels to categorical\n",
                "y_train_cat = to_categorical(y_train, num_classes)\n",
                "y_val_cat = to_categorical(y_val, num_classes)\n",
                "y_test_cat = to_categorical(y_test, num_classes)\n",
                "\n",
                "print(f\"\\nCategorical labels shape:\")\n",
                "print(f\"  Training:   {y_train_cat.shape}\")\n",
                "print(f\"  Validation: {y_val_cat.shape}\")\n",
                "print(f\"  Test:       {y_test_cat.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Build Model Architecture"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_model(input_shape, num_classes, model_type='dense'):\n",
                "    \"\"\"\n",
                "    Create a deep neural network for sign language classification.\n",
                "    \n",
                "    Args:\n",
                "        input_shape (int): Number of input features\n",
                "        num_classes (int): Number of output classes\n",
                "        model_type (str): 'dense' or 'deep_dense'\n",
                "    \n",
                "    Returns:\n",
                "        keras.Model: Compiled model\n",
                "    \"\"\"\n",
                "    if model_type == 'dense':\n",
                "        # Standard dense network\n",
                "        model = models.Sequential([\n",
                "            layers.Input(shape=(input_shape,)),\n",
                "            \n",
                "            # First block\n",
                "            layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
                "            layers.BatchNormalization(),\n",
                "            layers.Dropout(0.3),\n",
                "            \n",
                "            # Second block\n",
                "            layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
                "            layers.BatchNormalization(),\n",
                "            layers.Dropout(0.3),\n",
                "            \n",
                "            # Third block\n",
                "            layers.Dense(32, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
                "            layers.BatchNormalization(),\n",
                "            layers.Dropout(0.2),\n",
                "            \n",
                "            # Output layer\n",
                "            layers.Dense(num_classes, activation='softmax')\n",
                "        ], name='SignLanguageClassifier')\n",
                "    \n",
                "    elif model_type == 'deep_dense':\n",
                "        # Deeper network for more complex patterns\n",
                "        model = models.Sequential([\n",
                "            layers.Input(shape=(input_shape,)),\n",
                "            \n",
                "            layers.Dense(256, activation='relu'),\n",
                "            layers.BatchNormalization(),\n",
                "            layers.Dropout(0.4),\n",
                "            \n",
                "            layers.Dense(128, activation='relu'),\n",
                "            layers.BatchNormalization(),\n",
                "            layers.Dropout(0.3),\n",
                "            \n",
                "            layers.Dense(64, activation='relu'),\n",
                "            layers.BatchNormalization(),\n",
                "            layers.Dropout(0.3),\n",
                "            \n",
                "            layers.Dense(32, activation='relu'),\n",
                "            layers.BatchNormalization(),\n",
                "            layers.Dropout(0.2),\n",
                "            \n",
                "            layers.Dense(num_classes, activation='softmax')\n",
                "        ], name='DeepSignLanguageClassifier')\n",
                "    \n",
                "    return model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create model\n",
                "input_shape = X_train.shape[1]\n",
                "MODEL_TYPE = 'dense'  # Change to 'deep_dense' for deeper network\n",
                "\n",
                "model = create_model(input_shape, num_classes, model_type=MODEL_TYPE)\n",
                "\n",
                "# Display model architecture\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"MODEL ARCHITECTURE\")\n",
                "print(\"=\"*60)\n",
                "model.summary()\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Compile Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compile model\n",
                "LEARNING_RATE = 0.001\n",
                "\n",
                "model.compile(\n",
                "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
                "    loss='categorical_crossentropy',\n",
                "    metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()]\n",
                ")\n",
                "\n",
                "print(\"\\n‚úÖ Model compiled successfully\")\n",
                "print(f\"   Optimizer: Adam (lr={LEARNING_RATE})\")\n",
                "print(f\"   Loss: Categorical Crossentropy\")\n",
                "print(f\"   Metrics: Accuracy, Precision, Recall\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Configure Training Callbacks"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create timestamp for this training run\n",
                "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
                "model_name = f\"sign_language_model_{timestamp}\"\n",
                "\n",
                "# Define callbacks\n",
                "callbacks = [\n",
                "    # Save best model\n",
                "    ModelCheckpoint(\n",
                "        filepath=os.path.join(MODELS_DIR, 'best_model.keras'),\n",
                "        monitor='val_accuracy',\n",
                "        save_best_only=True,\n",
                "        mode='max',\n",
                "        verbose=1\n",
                "    ),\n",
                "    \n",
                "    # Early stopping\n",
                "    EarlyStopping(\n",
                "        monitor='val_loss',\n",
                "        patience=20,\n",
                "        restore_best_weights=True,\n",
                "        verbose=1\n",
                "    ),\n",
                "    \n",
                "    # Reduce learning rate on plateau\n",
                "    ReduceLROnPlateau(\n",
                "        monitor='val_loss',\n",
                "        factor=0.5,\n",
                "        patience=7,\n",
                "        min_lr=1e-7,\n",
                "        verbose=1\n",
                "    ),\n",
                "    \n",
                "    # TensorBoard logging\n",
                "    TensorBoard(\n",
                "        log_dir=os.path.join(LOGS_DIR, model_name),\n",
                "        histogram_freq=1,\n",
                "        write_graph=True\n",
                "    ),\n",
                "    \n",
                "    # CSV logging\n",
                "    CSVLogger(\n",
                "        filename=os.path.join(LOGS_DIR, f'{model_name}.csv'),\n",
                "        separator=',',\n",
                "        append=False\n",
                "    )\n",
                "]\n",
                "\n",
                "print(\"\\n‚úÖ Callbacks configured:\")\n",
                "print(\"   - ModelCheckpoint (save best model)\")\n",
                "print(\"   - EarlyStopping (patience=20)\")\n",
                "print(\"   - ReduceLROnPlateau (factor=0.5, patience=7)\")\n",
                "print(\"   - TensorBoard logging\")\n",
                "print(\"   - CSV logging\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Train Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training parameters\n",
                "EPOCHS = 150\n",
                "BATCH_SIZE = 32\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"STARTING TRAINING\")\n",
                "print(\"=\"*60)\n",
                "print(f\"Epochs: {EPOCHS}\")\n",
                "print(f\"Batch size: {BATCH_SIZE}\")\n",
                "print(f\"Training samples: {X_train.shape[0]}\")\n",
                "print(f\"Validation samples: {X_val.shape[0]}\")\n",
                "print(f\"Steps per epoch: {X_train.shape[0] // BATCH_SIZE}\")\n",
                "print(\"=\"*60 + \"\\n\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train model\n",
                "history = model.fit(\n",
                "    X_train, y_train_cat,\n",
                "    validation_data=(X_val, y_val_cat),\n",
                "    epochs=EPOCHS,\n",
                "    batch_size=BATCH_SIZE,\n",
                "    callbacks=callbacks,\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"‚úÖ TRAINING COMPLETED!\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Visualize Training History"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot training history\n",
                "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
                "\n",
                "# Accuracy\n",
                "axes[0, 0].plot(history.history['accuracy'], label='Train', linewidth=2)\n",
                "axes[0, 0].plot(history.history['val_accuracy'], label='Validation', linewidth=2)\n",
                "axes[0, 0].set_xlabel('Epoch', fontsize=11)\n",
                "axes[0, 0].set_ylabel('Accuracy', fontsize=11)\n",
                "axes[0, 0].set_title('Model Accuracy', fontsize=12, fontweight='bold')\n",
                "axes[0, 0].legend(fontsize=10)\n",
                "axes[0, 0].grid(alpha=0.3)\n",
                "\n",
                "# Loss\n",
                "axes[0, 1].plot(history.history['loss'], label='Train', linewidth=2)\n",
                "axes[0, 1].plot(history.history['val_loss'], label='Validation', linewidth=2)\n",
                "axes[0, 1].set_xlabel('Epoch', fontsize=11)\n",
                "axes[0, 1].set_ylabel('Loss', fontsize=11)\n",
                "axes[0, 1].set_title('Model Loss', fontsize=12, fontweight='bold')\n",
                "axes[0, 1].legend(fontsize=10)\n",
                "axes[0, 1].grid(alpha=0.3)\n",
                "\n",
                "# Precision\n",
                "axes[1, 0].plot(history.history['precision'], label='Train', linewidth=2)\n",
                "axes[1, 0].plot(history.history['val_precision'], label='Validation', linewidth=2)\n",
                "axes[1, 0].set_xlabel('Epoch', fontsize=11)\n",
                "axes[1, 0].set_ylabel('Precision', fontsize=11)\n",
                "axes[1, 0].set_title('Model Precision', fontsize=12, fontweight='bold')\n",
                "axes[1, 0].legend(fontsize=10)\n",
                "axes[1, 0].grid(alpha=0.3)\n",
                "\n",
                "# Recall\n",
                "axes[1, 1].plot(history.history['recall'], label='Train', linewidth=2)\n",
                "axes[1, 1].plot(history.history['val_recall'], label='Validation', linewidth=2)\n",
                "axes[1, 1].set_xlabel('Epoch', fontsize=11)\n",
                "axes[1, 1].set_ylabel('Recall', fontsize=11)\n",
                "axes[1, 1].set_title('Model Recall', fontsize=12, fontweight='bold')\n",
                "axes[1, 1].legend(fontsize=10)\n",
                "axes[1, 1].grid(alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('outputs/visualizations/training_history.png', dpi=300, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Training Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get best metrics\n",
                "best_epoch = np.argmax(history.history['val_accuracy'])\n",
                "best_val_acc = max(history.history['val_accuracy'])\n",
                "best_val_loss = history.history['val_loss'][best_epoch]\n",
                "final_train_acc = history.history['accuracy'][-1]\n",
                "final_val_acc = history.history['val_accuracy'][-1]\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"TRAINING SUMMARY\")\n",
                "print(\"=\"*60)\n",
                "print(f\"Total epochs trained: {len(history.history['accuracy'])}\")\n",
                "print(f\"Best epoch: {best_epoch + 1}\")\n",
                "print(f\"\\nBest Validation Metrics:\")\n",
                "print(f\"  Accuracy:  {best_val_acc*100:.2f}%\")\n",
                "print(f\"  Loss:      {best_val_loss:.4f}\")\n",
                "print(f\"\\nFinal Training Metrics:\")\n",
                "print(f\"  Train Accuracy:      {final_train_acc*100:.2f}%\")\n",
                "print(f\"  Validation Accuracy: {final_val_acc*100:.2f}%\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Save Training Metadata"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create training metadata\n",
                "training_metadata = {\n",
                "    'training_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
                "    'model_name': model_name,\n",
                "    'model_type': MODEL_TYPE,\n",
                "    'total_epochs': len(history.history['accuracy']),\n",
                "    'best_epoch': int(best_epoch + 1),\n",
                "    'batch_size': BATCH_SIZE,\n",
                "    'learning_rate': LEARNING_RATE,\n",
                "    'best_val_accuracy': float(best_val_acc),\n",
                "    'best_val_loss': float(best_val_loss),\n",
                "    'final_train_accuracy': float(final_train_acc),\n",
                "    'final_val_accuracy': float(final_val_acc),\n",
                "    'num_classes': num_classes,\n",
                "    'classes': label_encoder.classes_.tolist(),\n",
                "    'train_samples': int(X_train.shape[0]),\n",
                "    'val_samples': int(X_val.shape[0]),\n",
                "    'test_samples': int(X_test.shape[0])\n",
                "}\n",
                "\n",
                "# Save metadata\n",
                "os.makedirs('outputs/metrics', exist_ok=True)\n",
                "with open(f'outputs/metrics/training_metadata_{timestamp}.json', 'w') as f:\n",
                "    json.dump(training_metadata, f, indent=4)\n",
                "\n",
                "print(\"\\n‚úÖ Training metadata saved!\")\n",
                "print(f\"   File: outputs/metrics/training_metadata_{timestamp}.json\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Quick Test on Test Set"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load best model\n",
                "best_model = keras.models.load_model(os.path.join(MODELS_DIR, 'best_model.keras'))\n",
                "\n",
                "# Evaluate on test set\n",
                "test_results = best_model.evaluate(X_test, y_test_cat, verbose=0)\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"QUICK TEST SET EVALUATION\")\n",
                "print(\"=\"*60)\n",
                "print(f\"Test Loss:      {test_results[0]:.4f}\")\n",
                "print(f\"Test Accuracy:  {test_results[1]*100:.2f}%\")\n",
                "print(f\"Test Precision: {test_results[2]*100:.2f}%\")\n",
                "print(f\"Test Recall:    {test_results[3]*100:.2f}%\")\n",
                "print(\"=\"*60)\n",
                "print(\"\\nüìù For detailed evaluation, proceed to 05_model_evaluation.ipynb\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üéØ Summary\n",
                "\n",
                "Model training completed successfully!\n",
                "\n",
                "### What Was Done:\n",
                "- ‚úÖ Built deep neural network architecture\n",
                "- ‚úÖ Configured training with callbacks\n",
                "- ‚úÖ Trained model with early stopping\n",
                "- ‚úÖ Visualized training progress\n",
                "- ‚úÖ Saved best model and metadata\n",
                "- ‚úÖ Quick test set evaluation\n",
                "\n",
                "### What's Next?\n",
                "Proceed to **05_model_evaluation.ipynb** to:\n",
                "- Perform comprehensive model evaluation\n",
                "- Generate confusion matrix\n",
                "- Analyze per-class performance\n",
                "- Create detailed classification reports\n",
                "\n",
                "### TensorBoard\n",
                "To view training logs in TensorBoard:\n",
                "```bash\n",
                "tensorboard --logdir=outputs/logs\n",
                "```\n",
                "\n",
                "---"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}